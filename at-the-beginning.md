# At the Beginning

Nowadays, LLMs (Large Language Models) seem to be one of the most popular themes in the world. Technically speaking, most LLMs are large-scale transformer-based neural networks trained to generate texts (and follow instructions) by auto-regressive language modeling, which roughly is progressively predicting forthcoming texts based on known texts, on abundant corpus. Though trained models always "make" stupid mistakes when auto-regressively generating texts based on known texts along with previous predictions and it is not known that whether the ability of predicting any upcoming text could be considered as so-called intelligence or not, I do believe that LLMs do learn some essential knowledge on perception and analysis. LLMs' powerful capability of understanding sentences, generating texts and following instructions, has already surprised every ordinary person.

Under this circumstance, it may be interesting to apply LLMs to your works/studies/projects and **explore whether the perception and analysis inside a LLM would improve the target performance**.

At the beginning, even without much knowledge on LLMs, as long as knowing that LLMs could predict/generate texts, you could easily utilize a **LLM for** a **P**rocess **P**ipeline (**LLM4PP**) based on ready-made APIs and easy-to-use libraries. In this article, I will provide a quick start on that with some personal thoughts. I hope you could enjoy here! GLHF!

P.S. : Since I am a complete noob instead of a master, because of potential mistakes, this article is **for reference only**. I would appreciate it if you are willing to help by providing feedbacks/suggestions to bebetterest+at+outlook.com .
